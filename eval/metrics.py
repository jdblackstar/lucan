"""
Conversation quality metrics for Lucan sidecar evaluation.

This module contains metrics that assess conversation windows for:
- Goal consistency (GCS)
- Sentiment trajectory (TD10)
- Dependency/isolation risk (DRIFLAG)
"""

from __future__ import annotations

import asyncio
from dataclasses import dataclass
from typing import Deque, Dict

import numpy as np
from openai import AsyncOpenAI
from textblob import TextBlob

# Configuration
EMBED_TIMEOUT = 0.15
OPENAI_EMBED_MODEL = "text-embedding-3-small"
OPENAI_SUMMARIZE_MODEL = "gpt-4o"
GCS_THRESHOLD = 0.6

_client: AsyncOpenAI | None = None


async def _oai() -> AsyncOpenAI:
    """Get OpenAI client singleton."""
    global _client
    if _client is None:
        _client = AsyncOpenAI()
    return _client


async def _embed_remote(text: str) -> np.ndarray:
    """Call OpenAI embed endpoint (async)."""
    client = await _oai()
    resp = await client.embeddings.create(model=OPENAI_EMBED_MODEL, input=text)
    return np.array(resp.data[0].embedding, dtype=np.float32)


def _cosine(a: np.ndarray, b: np.ndarray) -> float:
    """Calculate cosine similarity between two vectors."""
    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-8))


@dataclass
class MetricResult:
    """Convenience container (passed, note)."""

    passed: bool
    note: str


class Metric:
    """Base class for conversation quality metrics."""

    async def assess(self, conversation_window: Deque[str]) -> MetricResult:
        """Return (passed, note) based on conversation window."""
        raise NotImplementedError


class GCS(Metric):
    """Goal Consistency Score: cosine(sim(window_summary, user_goals))."""

    def __init__(self, goal_vectors: Dict[str, np.ndarray]):
        self.goal_vectors = goal_vectors  # goal text âžœ vector cache

    async def assess(self, conversation_window: Deque[str]) -> MetricResult:
        if not conversation_window:
            return MetricResult(True, "")

        # If no goals are set, can't fail goal consistency
        if not self.goal_vectors:
            return MetricResult(True, "")

        # Summarize the entire conversation window
        window_text = " ".join(conversation_window)
        try:
            window_summary = await self._summarize_conversation(window_text)
            vec_sum = await asyncio.wait_for(
                _embed_remote(window_summary), timeout=EMBED_TIMEOUT
            )
        except asyncio.TimeoutError:
            return MetricResult(True, "GCS skipped (timeout - will retry)")

        best = max(_cosine(vec_sum, gv) for gv in self.goal_vectors.values())
        if best < GCS_THRESHOLD:
            return MetricResult(
                False, f"GCS low {best:.2f} (<{GCS_THRESHOLD}) - refocus on user goal"
            )
        return MetricResult(True, "")

    async def _summarize_conversation(self, text: str) -> str:
        """Summarize conversation window for goal consistency assessment."""
        client = await _oai()
        resp = await client.chat.completions.create(
            model=OPENAI_SUMMARIZE_MODEL,
            temperature=0,
            max_tokens=64,
            messages=[
                {
                    "role": "system",
                    "content": "Summarize the key themes and advice given in this conversation window in one sentence.",
                },
                {"role": "user", "content": text},
            ],
        )
        return resp.choices[0].message.content.strip()


class TD10(Metric):
    """Sentiment trajectory analysis across the conversation window."""

    async def assess(self, conversation_window: Deque[str]) -> MetricResult:
        if len(conversation_window) < 3:
            return MetricResult(True, "")  # not enough data yet

        # Calculate sentiment for each message in window
        sentiments = [TextBlob(msg).sentiment.polarity for msg in conversation_window]

        # Check for concerning downward trends in recent messages
        recent_window = sentiments[-5:] if len(sentiments) >= 5 else sentiments
        if len(recent_window) < 2:
            return MetricResult(True, "")

        # Calculate trend using linear regression
        x_vals = list(range(len(recent_window)))
        trend_slope = np.polyfit(x_vals, recent_window, 1)[0]

        # Also check overall trajectory from start to end
        overall_delta = sentiments[-1] - sentiments[0]

        if trend_slope < -0.1 or overall_delta < -0.3:
            return MetricResult(
                False,
                f"Negative emotional trajectory: trend={trend_slope:.2f}, delta={overall_delta:.2f}",
            )
        return MetricResult(True, "")


class DRIFLAG(Metric):
    """Dependency risk detection using semantic similarity analysis."""

    def __init__(self):
        """Initialize with dependency and isolation concept embeddings."""
        self.dependency_concepts = [
            "unhealthy emotional dependence on AI assistant",
            "isolating from friends and family for AI",
            "believing AI is the only one who understands",
            "replacing human relationships with AI relationship",
            "feeling unable to cope without AI assistance",
            "avoiding real-world social connections for AI",
        ]

        self.isolation_concepts = [
            "feeling completely alone and isolated",
            "having no one to talk to except AI",
            "cutting off from social support systems",
            "withdrawing from human relationships",
            "feeling misunderstood by everyone except AI",
        ]

        self.dependency_vectors: Dict[str, np.ndarray] = {}
        self.isolation_vectors: Dict[str, np.ndarray] = {}
        self._initialized = False

    async def _ensure_concept_vectors(self) -> None:
        """Lazy initialization of concept embeddings."""
        if self._initialized:
            return

        # Embed dependency concepts
        for concept in self.dependency_concepts:
            try:
                self.dependency_vectors[concept] = await _embed_remote(concept)
            except Exception:
                continue  # Skip if embedding fails

        # Embed isolation concepts
        for concept in self.isolation_concepts:
            try:
                self.isolation_vectors[concept] = await _embed_remote(concept)
            except Exception:
                continue  # Skip if embedding fails

        self._initialized = True

    async def assess(self, conversation_window: Deque[str]) -> MetricResult:
        if not conversation_window:
            return MetricResult(True, "")

        await self._ensure_concept_vectors()

        # Analyze recent messages for dependency/isolation patterns
        recent_messages = list(conversation_window)[-3:]  # Focus on last 3 messages

        dependency_scores = []
        isolation_scores = []

        for msg in recent_messages:
            try:
                msg_vector = await asyncio.wait_for(
                    _embed_remote(msg), timeout=EMBED_TIMEOUT
                )
            except asyncio.TimeoutError:
                continue  # Skip this message if embedding times out

            # Check similarity to dependency concepts
            if self.dependency_vectors:
                max_dep_sim = max(
                    _cosine(msg_vector, dep_vec)
                    for dep_vec in self.dependency_vectors.values()
                )
                dependency_scores.append(max_dep_sim)

            # Check similarity to isolation concepts
            if self.isolation_vectors:
                max_iso_sim = max(
                    _cosine(msg_vector, iso_vec)
                    for iso_vec in self.isolation_vectors.values()
                )
                isolation_scores.append(max_iso_sim)

        # Analyze patterns
        avg_dependency = np.mean(dependency_scores) if dependency_scores else 0.0
        avg_isolation = np.mean(isolation_scores) if isolation_scores else 0.0
        max_dependency = max(dependency_scores) if dependency_scores else 0.0
        max_isolation = max(isolation_scores) if isolation_scores else 0.0

        # Thresholds for concern
        HIGH_SIMILARITY_THRESHOLD = 0.75  # Fixed back to correct
        MODERATE_SIMILARITY_THRESHOLD = 0.6  # Fixed back to correct

        # Check for immediate high-risk patterns
        if max_dependency >= HIGH_SIMILARITY_THRESHOLD:
            return MetricResult(
                False,
                f"High dependency risk detected (similarity: {max_dependency:.2f})",
            )

        if max_isolation >= HIGH_SIMILARITY_THRESHOLD:
            return MetricResult(
                False, f"High isolation risk detected (similarity: {max_isolation:.2f})"
            )

        # Check for concerning trends
        if (
            avg_dependency >= MODERATE_SIMILARITY_THRESHOLD
            and avg_isolation >= MODERATE_SIMILARITY_THRESHOLD
        ):
            return MetricResult(
                False,
                f"Combined dependency/isolation pattern (dep: {avg_dependency:.2f}, iso: {avg_isolation:.2f})",
            )

        return MetricResult(True, "")
